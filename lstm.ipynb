{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonliang35/Polish-POS-Tagging/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm4IGCtvXxsH"
      },
      "source": [
        "### This script predicts the ctag of a word using character-level information by LSTM (Long Short-term Memory) units."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt6Tuu-7YF6N",
        "outputId": "4339bdc6-aabe-441d-f10a-11dacc989ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/UIUC/pos_tagging/Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLU7T2mvYHSO",
        "outputId": "a1d93506-7a26-498e-f560-843381e5db29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UIUC/pos_tagging/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TX4kK3vXxsJ"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChFXdgD5XxsJ"
      },
      "source": [
        "Following is a function used to parse xml into list of list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRHmRFsVXxsK"
      },
      "outputs": [],
      "source": [
        "def read_data(path):\n",
        "    ## Parse xml file\n",
        "    tree = ET.parse(path)\n",
        "    root = tree.getroot()\n",
        "    ## Construct list of list\n",
        "    data = []\n",
        "    label = []\n",
        "    lexicon = []\n",
        "    for chunk in root:\n",
        "        cur_data = []\n",
        "        cur_label = []\n",
        "        cur_lex = []\n",
        "        for tok in chunk:\n",
        "            if tok.tag != 'ns':\n",
        "                cur_data.append(tok.find('orth').text.lower())\n",
        "                cur_lex.append(tok.find('lex').find('base').text.lower())\n",
        "                cur_label.append(tok.find('lex').find('ctag').text)\n",
        "        data.append(cur_data)\n",
        "        label.append(cur_label)\n",
        "        lexicon.append(cur_lex)\n",
        "    return data,label,lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGSlqSDlXxsK"
      },
      "outputs": [],
      "source": [
        "# Input data\n",
        "trdata, trlabel, trlemma = read_data('../Data/train.xml')\n",
        "valdata, vallabel, vallemma = read_data('../Data/validate.xml')\n",
        "tedata, telabel, telemma = read_data('../Data/test.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf4-U7LhXxsK"
      },
      "outputs": [],
      "source": [
        "# Combine training and validation data.\n",
        "trdata += valdata\n",
        "trlabel += vallabel\n",
        "trlemma += vallemma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore position in a sentence\n",
        "Xtrain = []\n",
        "ytrain = []\n",
        "Xtest = []\n",
        "ytest = []\n",
        "for sent in trdata:\n",
        "    for w in sent:\n",
        "        Xtrain.append(list(w))\n",
        "for sent in trlabel:\n",
        "    ytrain += sent\n",
        "for sent in tedata:\n",
        "    for w in sent:\n",
        "        Xtest.append(list(w))\n",
        "for sent in telabel:\n",
        "    ytest += sent"
      ],
      "metadata": {
        "id": "jp6XlBoVlcO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All Polish characters\n",
        "all_chars = []\n",
        "max_len = 0\n",
        "for w in Xtrain:\n",
        "    if len(w) > max_len:\n",
        "        max_len = len(w)\n",
        "    all_chars.extend(w)\n",
        "vocab = list(set(all_chars))"
      ],
      "metadata": {
        "id": "EmBOqGUjfVIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform characters into indices\n",
        "vocab_set = set(vocab)\n",
        "vocab.append('<UNK>')\n",
        "vocab_dict = {vocab[i]:i for i in range(len(vocab))}\n",
        "vocab_dict_inv = {i:vocab[i] for i in range(len(vocab))}\n",
        "Xtrain_enc = []\n",
        "Xtest_enc = []\n",
        "for w in Xtrain:\n",
        "    Xtrain_enc.append([vocab_dict[i] for i in w])\n",
        "for w in Xtest:\n",
        "    tmp = []\n",
        "    for c in list(w):\n",
        "        if c in vocab_set:\n",
        "            tmp.append(vocab_dict[c])\n",
        "        else:\n",
        "            tmp.append(vocab_dict['<UNK>'])\n",
        "    Xtest_enc.append(tmp)"
      ],
      "metadata": {
        "id": "Y0Om20w-sc1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences\n",
        "Xtrain_pad = keras.preprocessing.sequence.pad_sequences(Xtrain_enc)\n",
        "Xtest_pad = keras.preprocessing.sequence.pad_sequences(Xtest_enc, maxlen=Xtrain_pad.shape[1])"
      ],
      "metadata": {
        "id": "djnEXOPrZNdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The lemma undergo the same process as orth form\n",
        "Xtrain_lem = []\n",
        "Xtest_lem = []\n",
        "for sent in trlemma:\n",
        "    for w in sent:\n",
        "        Xtrain_lem.append(list(w))\n",
        "for sent in telemma:\n",
        "    for w in sent:\n",
        "        Xtest_lem.append(list(w))\n",
        "assert len(Xtrain) == len(Xtrain_lem)\n",
        "\n",
        "all_chars_lem = []\n",
        "for w in Xtrain_lem:\n",
        "    all_chars_lem.extend(w)\n",
        "vocab_lem = list(set(all_chars_lem))\n",
        "vocab_set_lem = set(vocab_lem)\n",
        "vocab_lem.append('<UNK>')\n",
        "vocab_dict_lem = {vocab_lem[i]:i for i in range(len(vocab_lem))}\n",
        "\n",
        "Xtrain_enc_lem = []\n",
        "Xtest_enc_lem = []\n",
        "for w in Xtrain_lem:\n",
        "    Xtrain_enc_lem.append([vocab_dict_lem[i] for i in w])\n",
        "for w in Xtest_lem:\n",
        "    tmp = []\n",
        "    for c in list(w):\n",
        "        if c in vocab_set_lem:\n",
        "            tmp.append(vocab_dict_lem[c])\n",
        "        else:\n",
        "            tmp.append(vocab_dict_lem['<UNK>'])\n",
        "    Xtest_enc_lem.append(tmp)\n",
        "\n",
        "Xtrain_pad_lem = keras.preprocessing.sequence.pad_sequences(Xtrain_enc_lem)\n",
        "Xtest_pad_lem = keras.preprocessing.sequence.pad_sequences(Xtest_enc_lem, maxlen=Xtrain_pad_lem.shape[1])"
      ],
      "metadata": {
        "id": "87gZGOCPy0H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode ctags as vec\n",
        "ctags = list(set(ytrain + ytest))\n",
        "label_enc = LabelEncoder().fit(ctags)\n",
        "ytrain = label_enc.transform(ytrain)\n",
        "ytest = label_enc.transform(ytest)\n",
        "ytrain_oh = tf.one_hot(ytrain, len(label_enc.classes_))\n",
        "ytest_oh = tf.one_hot(ytest, len(label_enc.classes_))"
      ],
      "metadata": {
        "id": "PP5THi6WOtGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the baseline LSTM model without lemma..."
      ],
      "metadata": {
        "id": "YSlxC5ryZN80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype='int32')\n",
        "x = layers.Embedding(len(vocab), 128)(inputs)\n",
        "x = layers.LSTM(64)(x)\n",
        "outputs = layers.Dense(len(label_enc.classes_), activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"Adam\", loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wEoUIbyZNbP",
        "outputId": "494ad30c-8f7b-4c01-f4f6-1ddd4aa81ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 128)         15616     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 926)               60190     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125,214\n",
            "Trainable params: 125,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain_pad, ytrain_oh, epochs=10)"
      ],
      "metadata": {
        "id": "tfsfyWEX5nUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2881a2d0-6f62-4542-bd58-edec9c4d3e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30394/30394 [==============================] - 688s 23ms/step - loss: 1.3409 - accuracy: 0.6303\n",
            "Epoch 2/10\n",
            "30394/30394 [==============================] - 677s 22ms/step - loss: 0.9276 - accuracy: 0.7106\n",
            "Epoch 3/10\n",
            "30394/30394 [==============================] - 672s 22ms/step - loss: 0.8569 - accuracy: 0.7276\n",
            "Epoch 4/10\n",
            "30394/30394 [==============================] - 671s 22ms/step - loss: 0.8208 - accuracy: 0.7371\n",
            "Epoch 5/10\n",
            "30394/30394 [==============================] - 669s 22ms/step - loss: 0.7985 - accuracy: 0.7426\n",
            "Epoch 6/10\n",
            "30394/30394 [==============================] - 669s 22ms/step - loss: 0.7825 - accuracy: 0.7466\n",
            "Epoch 7/10\n",
            "30394/30394 [==============================] - 671s 22ms/step - loss: 0.7903 - accuracy: 0.7449\n",
            "Epoch 8/10\n",
            "30394/30394 [==============================] - 677s 22ms/step - loss: 0.7700 - accuracy: 0.7503\n",
            "Epoch 9/10\n",
            "30394/30394 [==============================] - 672s 22ms/step - loss: 0.7584 - accuracy: 0.7526\n",
            "Epoch 10/10\n",
            "30394/30394 [==============================] - 662s 22ms/step - loss: 0.7531 - accuracy: 0.7539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb28d458390>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(Xtest_pad, ytest_oh)"
      ],
      "metadata": {
        "id": "PCSV1Rhz5nWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29f9d80-ee36-4a61-c6d8-9bf0fc123584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7592/7592 [==============================] - 92s 12ms/step - loss: 0.7733 - accuracy: 0.7510\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7732653021812439, 0.7509972453117371]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now, try incorporating lemma into LSTM..."
      ],
      "metadata": {
        "id": "fOhCnlG7x4U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Orth form\n",
        "orth_input = keras.Input(shape=(None,), dtype='int32')\n",
        "xo = layers.Embedding(len(vocab), 128)(orth_input)\n",
        "xo = layers.LSTM(64)(xo)\n",
        "\n",
        "# Word lemma\n",
        "lem_input = keras.Input(shape=(None,), dtype='int32')\n",
        "xl = layers.Embedding(len(vocab_lem), 128)(lem_input)\n",
        "xl = layers.LSTM(64)(xl)\n",
        "\n",
        "# Final classification\n",
        "concat = layers.Concatenate()([xo, xl])\n",
        "outputs = layers.Dense(len(label_enc.classes_), activation='softmax')(concat)\n",
        "model2 = keras.Model([orth_input, lem_input], outputs)\n",
        "model2.compile(optimizer=\"Adam\", loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FLjvpVxzJsW",
        "outputId": "1e415178-19ed-4eaa-fcb6-c87472c97a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 128)    15616       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 128)    15488       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           49408       ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 64)           49408       ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128)          0           ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 926)          119454      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 249,374\n",
            "Trainable params: 249,374\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit([Xtrain_pad, Xtrain_pad_lem], ytrain_oh, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-dRpMQK0hN3",
        "outputId": "2166fd6d-6ad5-4d9d-c842-5ac1fc91e5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    3/30394 [..............................] - ETA: 16:47 - loss: 6.8248 - accuracy: 0.0729    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30394/30394 [==============================] - 1022s 34ms/step - loss: 0.9007 - accuracy: 0.7317\n",
            "Epoch 2/10\n",
            "30394/30394 [==============================] - 1018s 33ms/step - loss: 0.6172 - accuracy: 0.7854\n",
            "Epoch 3/10\n",
            "30394/30394 [==============================] - 1015s 33ms/step - loss: 0.5804 - accuracy: 0.7933\n",
            "Epoch 4/10\n",
            "30394/30394 [==============================] - 1016s 33ms/step - loss: 0.5638 - accuracy: 0.7970\n",
            "Epoch 5/10\n",
            "30394/30394 [==============================] - 1015s 33ms/step - loss: 0.5536 - accuracy: 0.7993\n",
            "Epoch 6/10\n",
            "30394/30394 [==============================] - 1011s 33ms/step - loss: 0.5469 - accuracy: 0.8007\n",
            "Epoch 7/10\n",
            "30394/30394 [==============================] - 1008s 33ms/step - loss: 0.5419 - accuracy: 0.8017\n",
            "Epoch 8/10\n",
            "30394/30394 [==============================] - 1013s 33ms/step - loss: 0.5382 - accuracy: 0.8028\n",
            "Epoch 9/10\n",
            "30394/30394 [==============================] - 1016s 33ms/step - loss: 0.5349 - accuracy: 0.8036\n",
            "Epoch 10/10\n",
            "30394/30394 [==============================] - 1016s 33ms/step - loss: 0.5325 - accuracy: 0.8044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd20ac3cf90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate([Xtest_pad, Xtest_pad_lem], ytest_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUu3Sxm9x9hk",
        "outputId": "0b56cc1d-134b-4527-ca0a-ca87d656f35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   7/7592 [..............................] - ETA: 2:10 - loss: 0.4120 - accuracy: 0.8259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7592/7592 [==============================] - 127s 17ms/step - loss: 0.5607 - accuracy: 0.8018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.560661256313324, 0.8018055558204651]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is 0.05 better in accuracy!"
      ],
      "metadata": {
        "id": "LdBJ1wN6N9F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Bi-LSTM with Attention"
      ],
      "metadata": {
        "id": "06VkBA4_YeFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Attention Network\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "class Attention(keras.layers.Layer):\n",
        "    def __init__(self, return_sequences=False):\n",
        "        # If return_sequences==True, the output is the hidden state weighted by the attention weights.\n",
        "        # If return_sequences==False, the output is further summed up.\n",
        "        self.return_sequences = return_sequences\n",
        "        super(Attention,self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1), initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[-2],1), initializer=\"zeros\")\n",
        "        super(Attention,self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "        return K.sum(output, axis=1)"
      ],
      "metadata": {
        "id": "ed1Zg4ztYhLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Orth form\n",
        "orth_input = keras.Input(shape=(Xtrain_pad.shape[1],), dtype='int32')\n",
        "xo = layers.Embedding(len(vocab), 128)(orth_input)\n",
        "xo = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(xo)\n",
        "xo = Attention()(xo)\n",
        "\n",
        "# Word lemma\n",
        "lem_input = keras.Input(shape=(Xtrain_pad_lem.shape[1],), dtype='int32')\n",
        "xl = layers.Embedding(len(vocab_lem), 128)(lem_input)\n",
        "xl = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(xl)\n",
        "xl = Attention()(xl)\n",
        "\n",
        "# Final classification\n",
        "concat = layers.Concatenate()([xo, xl])\n",
        "outputs = layers.Dense(len(label_enc.classes_), activation='softmax')(concat)\n",
        "model4 = keras.Model([orth_input, lem_input], outputs)\n",
        "model4.compile(optimizer=\"Adam\", loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIb_Oym4YhQj",
        "outputId": "a188df06-954a-4818-9210-4920f9efd198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 54)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 54)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 54, 128)      15616       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 54, 128)      15488       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 54, 128)      98816       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 54, 128)     98816       ['embedding_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 128)          182         ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " attention_1 (Attention)        (None, 128)          182         ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256)          0           ['attention[0][0]',              \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 926)          237982      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 467,082\n",
            "Trainable params: 467,082\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.fit([Xtrain_pad, Xtrain_pad_lem], ytrain_oh, epochs=10)"
      ],
      "metadata": {
        "id": "J_T6a91PYhN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421fc4ad-5b51-4c4c-f18c-08252530dd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30394/30394 [==============================] - 546s 18ms/step - loss: 1.1687 - accuracy: 0.6779\n",
            "Epoch 2/10\n",
            "30394/30394 [==============================] - 536s 18ms/step - loss: 0.6230 - accuracy: 0.7852\n",
            "Epoch 3/10\n",
            "30394/30394 [==============================] - 571s 19ms/step - loss: 0.5665 - accuracy: 0.7967\n",
            "Epoch 4/10\n",
            "30394/30394 [==============================] - 567s 19ms/step - loss: 0.5405 - accuracy: 0.8023\n",
            "Epoch 5/10\n",
            "30394/30394 [==============================] - 561s 18ms/step - loss: 0.5264 - accuracy: 0.8056\n",
            "Epoch 6/10\n",
            "30394/30394 [==============================] - 559s 18ms/step - loss: 0.5157 - accuracy: 0.8082\n",
            "Epoch 7/10\n",
            "30394/30394 [==============================] - 556s 18ms/step - loss: 0.5084 - accuracy: 0.8097\n",
            "Epoch 8/10\n",
            "30394/30394 [==============================] - 524s 17ms/step - loss: 0.5026 - accuracy: 0.8113\n",
            "Epoch 9/10\n",
            "30394/30394 [==============================] - 519s 17ms/step - loss: 0.4981 - accuracy: 0.8127\n",
            "Epoch 10/10\n",
            "30394/30394 [==============================] - 521s 17ms/step - loss: 0.4946 - accuracy: 0.8136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e3f79df10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate([Xtest_pad, Xtest_pad_lem], ytest_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xoEYHJxBHHC",
        "outputId": "27942ed1-9b96-45b4-f677-3da40c9b760f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7592/7592 [==============================] - 60s 8ms/step - loss: 0.5256 - accuracy: 0.8069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5255862474441528, 0.8068938255310059]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using attention mechanism is almost the same (+0.005). This is probably because words are not as long as sentences where attention is more powerful."
      ],
      "metadata": {
        "id": "VfOfMLiLSGd6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}